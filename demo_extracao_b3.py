"""
Demonstra√ß√£o interativa de extra√ß√£o de dados B3
VERS√ÉO MELHORADA - Com suporte a per√≠odos customizados
"""

import yfinance as yf
import boto3
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO
import time
import argparse

s3 = boto3.client('s3')

# Configura√ß√µes
BUCKET = 'pipeline-b3-lab-buzato'
TICKERS = [
    ('^BVSP', 'IBOV', '√çndice Bovespa'),
    ('PETR4.SA', 'PETR4', 'Petrobras PN'),
    ('VALE3.SA', 'VALE3', 'Vale ON'),
    ('ITUB4.SA', 'ITUB4', 'Ita√∫ Unibanco PN'),
    ('ITSA4.SA', 'ITSA4', 'Ita√∫sa PN')
]

# OP√á√ïES DE PER√çODO
PERIOD_OPTIONS = {
    '5d': '5 dias',
    '1mo': '1 m√™s (~21 dias √∫teis)',
    '3mo': '3 meses (~63 dias √∫teis)',
    '6mo': '6 meses (~126 dias √∫teis)',
    '1y': '1 ano (~250 dias √∫teis)',
    '2y': '2 anos (~500 dias √∫teis)',
    '5y': '5 anos (~1250 dias √∫teis)',
    '10y': '10 anos',
    'ytd': 'Do in√≠cio do ano at√© hoje',
    'max': 'M√°ximo dispon√≠vel (desde IPO)'
}

def print_header(text):
    """Imprime cabe√ßalho formatado"""
    print("\n" + "="*80)
    print(f"  {text}")
    print("="*80)

def print_section(text):
    """Imprime se√ß√£o formatada"""
    print("\n" + "-"*80)
    print(f"  {text}")
    print("-"*80)

def show_dataframe_sample(df, ticker_name):
    """Mostra amostra dos dados extra√≠dos"""
    print(f"\nüìä Dados extra√≠dos de {ticker_name}:")
    print(f"   Shape: {df.shape[0]} linhas x {df.shape[1]} colunas")
    print(f"\n   Per√≠odo: {df['data'].min()} at√© {df['data'].max()}")
    print(f"   Total de dias: {df.shape[0]}")
    print(f"\n   Colunas: {list(df.columns)}")
    print(f"\n   Primeiras linhas:")
    print(df.head(3).to_string(index=False))
    print(f"\n   √öltimas linhas:")
    print(df.tail(3).to_string(index=False))

def extract_with_custom_dates(ticker_yahoo, start_date, end_date):
    """
    Extrai dados com datas espec√≠ficas
    
    Args:
        ticker_yahoo: S√≠mbolo do Yahoo (ex: 'PETR4.SA')
        start_date: Data inicial (datetime ou string 'YYYY-MM-DD')
        end_date: Data final (datetime ou string 'YYYY-MM-DD')
    """
    if isinstance(start_date, str):
        start_date = datetime.strptime(start_date, '%Y-%m-%d')
    if isinstance(end_date, str):
        end_date = datetime.strptime(end_date, '%Y-%m-%d')
    
    print(f"   Per√≠odo customizado: {start_date.date()} at√© {end_date.date()}")
    
    df = yf.download(
        ticker_yahoo,
        start=start_date.strftime('%Y-%m-%d'),
        end=end_date.strftime('%Y-%m-%d'),
        interval='1d',
        progress=False
    )
    
    return df

def main(period='1mo', custom_start=None, custom_end=None, tickers_filter=None):
    print_header("EXTRA√á√ÉO DE DADOS B3 - VERS√ÉO CUSTOMIZ√ÅVEL")
    
    # Mostrar per√≠odo selecionado
    if custom_start and custom_end:
        period_desc = f"Per√≠odo customizado: {custom_start} at√© {custom_end}"
    else:
        period_desc = f"Per√≠odo: {period} ({PERIOD_OPTIONS.get(period, 'Desconhecido')})"
    
    print(f"\nüìÖ {period_desc}")
    print(f"üïê In√≠cio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Filtrar tickers se solicitado
    if tickers_filter:
        tickers_to_process = [t for t in TICKERS if t[1] in tickers_filter]
        if not tickers_to_process:
            print(f"\n‚ö†Ô∏è  AVISO: Nenhum ticker encontrado em {tickers_filter}")
            print(f"Tickers dispon√≠veis: {[t[1] for t in TICKERS]}")
            return
    else:
        tickers_to_process = TICKERS
    
    print(f"üìà Tickers selecionados: {[t[1] for t in tickers_to_process]}")
    
    results = []
    
    # Para cada ticker
    for i, (ticker_yahoo, ticker_clean, ticker_desc) in enumerate(tickers_to_process, 1):
        
        print_section(f"TICKER {i}/{len(tickers_to_process)}: {ticker_desc} ({ticker_clean})")
        
        print(f"\n[Etapa 1] üåê Conectando com Yahoo Finance...")
        time.sleep(0.5)
        
        try:
            print(f"\n[Etapa 2] üì• Baixando dados hist√≥ricos...")
            
            # Download dos dados
            start_time = time.time()
            
            if custom_start and custom_end:
                df = extract_with_custom_dates(ticker_yahoo, custom_start, custom_end)
            else:
                df = yf.download(
                    ticker_yahoo, 
                    period=period, 
                    interval='1d',
                    progress=False
                )
            
            download_time = time.time() - start_time
            
            if df.empty:
                print(f"\n   ‚ö†Ô∏è  AVISO: Sem dados dispon√≠veis para {ticker_yahoo}")
                continue
            
            print(f"   ‚úì Download conclu√≠do em {download_time:.2f}s")
            print(f"   ‚úì Registros obtidos: {len(df)}")
            
            # Processamento
            print(f"\n[Etapa 3] üîÑ Processando dados (SCHEMA SPARK-COMPAT√çVEL)...")
            
            # Reset index e renomear colunas
            df = df.reset_index()
            
            # Padronizar nomes de colunas
            df.columns = ['data', 'abertura', 'maxima', 'minima', 'fechamento', 'volume']
            
            # Converter data para datetime64[ms] (Spark-compat√≠vel)
            df['data'] = pd.to_datetime(df['data']).dt.tz_localize(None)
            df['data'] = df['data'].astype('datetime64[ms]')
            
            # Garantir tipos corretos
            df['abertura'] = df['abertura'].astype('float64')
            df['maxima'] = df['maxima'].astype('float64')
            df['minima'] = df['minima'].astype('float64')
            df['fechamento'] = df['fechamento'].astype('float64')
            df['volume'] = df['volume'].astype('int64')
            
            # Adicionar ticker
            df['ticker'] = ticker_clean
            df['ticker'] = df['ticker'].astype('string')
            
            # Reordenar colunas
            df = df[['ticker', 'data', 'abertura', 'maxima', 'minima', 'fechamento', 'volume']]
            
            print(f"   ‚úì Schema validado e otimizado para Spark")
            
            # Mostrar amostra
            show_dataframe_sample(df, ticker_desc)
            
            # Converter para Parquet
            print(f"\n[Etapa 4] üì¶ Convertendo para formato Parquet...")
            buffer = BytesIO()
            start_time = time.time()
            
            df.to_parquet(
                buffer, 
                engine='pyarrow',
                index=False,
                compression='snappy',
                coerce_timestamps='ms',
                allow_truncated_timestamps=True,
                use_deprecated_int96_timestamps=False
            )
            
            buffer.seek(0)
            conversion_time = time.time() - start_time
            
            parquet_size = len(buffer.getvalue())
            print(f"   ‚úì Convers√£o conclu√≠da em {conversion_time:.3f}s")
            print(f"   ‚úì Tamanho do arquivo: {parquet_size:,} bytes ({parquet_size/1024:.2f} KB)")
            
            # Estat√≠sticas de compress√£o
            csv_size = len(df.to_csv(index=False))
            compression_ratio = (1 - parquet_size/csv_size) * 100
            print(f"   ‚úì Compress√£o vs CSV: {compression_ratio:.1f}% menor")
            
            # Upload para S3 (particionado por data)
            print(f"\n[Etapa 5] ‚òÅÔ∏è  Enviando para AWS S3...")
            
            # Agrupar por data para criar m√∫ltiplos arquivos se necess√°rio
            dates_in_data = df['data'].dt.date.unique()
            files_uploaded = []
            
            for date in dates_in_data:
                date_str = date.strftime('%Y-%m-%d')
                df_date = df[df['data'].dt.date == date]
                
                # Criar buffer para esta data
                date_buffer = BytesIO()
                df_date.to_parquet(
                    date_buffer,
                    engine='pyarrow',
                    index=False,
                    compression='snappy',
                    coerce_timestamps='ms',
                    allow_truncated_timestamps=True
                )
                date_buffer.seek(0)
                
                # Key no S3
                key = f'raw/date={date_str}/{ticker_clean}_{date_str}.parquet'
                
                # Upload
                s3.put_object(
                    Bucket=BUCKET,
                    Key=key,
                    Body=date_buffer.getvalue(),
                    ContentType='application/octet-stream',
                    Metadata={
                        'ticker': ticker_clean,
                        'extraction_date': datetime.now().isoformat(),
                        'records': str(len(df_date)),
                        'period': period if not custom_start else 'custom'
                    }
                )
                files_uploaded.append(key)
            
            upload_time = time.time() - start_time
            
            print(f"   ‚úì Upload conclu√≠do em {upload_time:.2f}s")
            print(f"   ‚úì {len(files_uploaded)} arquivo(s) criado(s)")
            print(f"   ‚úì Bucket: s3://{BUCKET}/")
            
            # Verificar uploads
            print(f"\n[Etapa 6] ‚úÖ Verificando uploads no S3...")
            for key in files_uploaded[:3]:  # Mostrar apenas primeiros 3
                response = s3.head_object(Bucket=BUCKET, Key=key)
                print(f"   ‚úì {key}")
                print(f"     Tamanho: {response['ContentLength']:,} bytes")
            
            if len(files_uploaded) > 3:
                print(f"   ... e mais {len(files_uploaded) - 3} arquivo(s)")
            
            # Sucesso
            results.append({
                'ticker': ticker_clean,
                'status': 'SUCCESS',
                'records': len(df),
                'files': len(files_uploaded),
                'date_range': f"{df['data'].min().date()} at√© {df['data'].max().date()}",
                'download_time': download_time,
                'upload_time': upload_time
            })
            
            print(f"\n   ‚úÖ {ticker_desc} processado com SUCESSO!")
            
        except Exception as e:
            print(f"\n   ‚ùå ERRO ao processar {ticker_yahoo}:")
            print(f"   {str(e)}")
            import traceback
            print(traceback.format_exc())
            results.append({
                'ticker': ticker_clean,
                'status': 'FAILED',
                'error': str(e)
            })
        
        # Pausa entre tickers
        if i < len(tickers_to_process):
            print(f"\n   ‚è≥ Aguardando 2 segundos antes do pr√≥ximo ticker...")
            time.sleep(2)
    
    # Resumo final
    print_header("RESUMO DA EXTRA√á√ÉO")
    
    success = [r for r in results if r['status'] == 'SUCCESS']
    failed = [r for r in results if r['status'] == 'FAILED']
    
    print(f"\nüìä Estat√≠sticas:")
    print(f"   Total de tickers processados: {len(tickers_to_process)}")
    print(f"   ‚úÖ Sucessos: {len(success)}")
    print(f"   ‚ùå Falhas: {len(failed)}")
    
    if success:
        total_records = sum(r['records'] for r in success)
        total_files = sum(r['files'] for r in success)
        avg_download = sum(r['download_time'] for r in success) / len(success)
        avg_upload = sum(r['upload_time'] for r in success) / len(success)
        
        print(f"\n   Total de registros extra√≠dos: {total_records:,}")
        print(f"   Total de arquivos criados: {total_files}")
        print(f"   Tempo m√©dio de download: {avg_download:.2f}s")
        print(f"   Tempo m√©dio de upload: {avg_upload:.2f}s")
        
        print(f"\nüìÖ Per√≠odos de dados:")
        for r in success:
            print(f"   {r['ticker']}: {r['date_range']} ({r['records']} dias)")
        
        print(f"\nüìÅ Arquivos criados no S3 (particionados por data):")
        print(f"   Padr√£o: s3://{BUCKET}/raw/date=YYYY-MM-DD/TICKER_YYYY-MM-DD.parquet")
    
    if failed:
        print(f"\n‚ùå Tickers com falha:")
        for r in failed:
            print(f"   ‚úó {r['ticker']}: {r.get('error', 'Erro desconhecido')}")
    
    print(f"\nüïê T√©rmino: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print_header("EXTRA√á√ÉO CONCLU√çDA - PRONTO PARA PROCESSAR NO GLUE!")
    
    print("\nüéØ Pr√≥ximos passos:")
    print("   1. Lambda ser√° acionada automaticamente pelo S3")
    print("   2. Glue Job processar√° os dados")
    print("   3. Dados refinados estar√£o dispon√≠veis no Athena")
    print("\nüí° Monitorar:")
    print("   - CloudWatch Logs: /aws/lambda/b3-s3-trigger-lambda")
    print("   - Glue Jobs: AWS Console ‚Üí Glue ‚Üí ETL jobs ‚Üí b3-etl-job")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='Extra√ß√£o de dados B3 com per√≠odos customiz√°veis',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:

  # Extrair √∫ltimos 5 dias (padr√£o)
  python demo_extracao_b3.py

  # Extrair 1 ano de dados
  python demo_extracao_b3.py --period 1y

  # Extrair 5 anos de dados
  python demo_extracao_b3.py --period 5y

  # Extrair m√°ximo dispon√≠vel
  python demo_extracao_b3.py --period max

  # Extrair apenas PETR4 e VALE3
  python demo_extracao_b3.py --period 1y --tickers PETR4 VALE3

  # Per√≠odo customizado (datas espec√≠ficas)
  python demo_extracao_b3.py --start 2020-01-01 --end 2025-12-31

  # Per√≠odo customizado + tickers espec√≠ficos
  python demo_extracao_b3.py --start 2023-01-01 --end 2024-12-31 --tickers IBOV PETR4

Per√≠odos dispon√≠veis:
  5d   - 5 dias
  1mo  - 1 m√™s (~21 dias √∫teis)
  3mo  - 3 meses (~63 dias √∫teis)
  6mo  - 6 meses (~126 dias √∫teis)
  1y   - 1 ano (~250 dias √∫teis) ‚úÖ RECOMENDADO
  2y   - 2 anos (~500 dias √∫teis)
  5y   - 5 anos (~1250 dias √∫teis)
  10y  - 10 anos
  ytd  - Do in√≠cio do ano at√© hoje
  max  - M√°ximo dispon√≠vel (desde IPO)
        """
    )
    
    parser.add_argument(
        '--period',
        default='1mo',
        choices=list(PERIOD_OPTIONS.keys()),
        help='Per√≠odo para extra√ß√£o (padr√£o: 1mo)'
    )
    
    parser.add_argument(
        '--start',
        type=str,
        help='Data inicial (formato: YYYY-MM-DD) - sobrescreve --period'
    )
    
    parser.add_argument(
        '--end',
        type=str,
        help='Data final (formato: YYYY-MM-DD) - requer --start'
    )
    
    parser.add_argument(
        '--tickers',
        nargs='+',
        help='Tickers espec√≠ficos para extrair (ex: IBOV PETR4 VALE3)'
    )
    
    args = parser.parse_args()
    
    # Valida√ß√µes
    if args.end and not args.start:
        parser.error("--end requer --start")
    
    if args.start and args.end:
        try:
            start_dt = datetime.strptime(args.start, '%Y-%m-%d')
            end_dt = datetime.strptime(args.end, '%Y-%m-%d')
            if start_dt >= end_dt:
                parser.error("--start deve ser anterior a --end")
        except ValueError:
            parser.error("Datas devem estar no formato YYYY-MM-DD")
    
    # Executar
    main(
        period=args.period,
        custom_start=args.start,
        custom_end=args.end,
        tickers_filter=args.tickers
    )